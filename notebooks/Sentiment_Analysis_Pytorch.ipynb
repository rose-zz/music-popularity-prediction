{"cells":[{"cell_type":"markdown","source":["# Sentimental Analysis with Pytorch on Smaller Subset of Data"],"metadata":{"id":"-JQBLJ6WeG-y"},"id":"-JQBLJ6WeG-y"},{"cell_type":"markdown","source":["To run these files please specify the file path to the folder"],"metadata":{"id":"9G6fN4pneNI_"},"id":"9G6fN4pneNI_"},{"cell_type":"code","source":["folder_path = '/content/drive/MyDrive/Colab Notebooks/381 Final Project/ML Final Project/'"],"metadata":{"id":"dxibQR4XeTT2"},"id":"dxibQR4XeTT2","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"9efd4b89","metadata":{"id":"9efd4b89","outputId":"2c93f9cb-e255-4b36-d7be-e939a362678c"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to\n","[nltk_data]     C:\\Users\\jenni\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to\n","[nltk_data]     C:\\Users\\jenni\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":247,"metadata":{},"output_type":"execute_result"}],"source":["import nltk as nl\n","import pandas as pd\n","from gensim.utils import simple_preprocess\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","from sklearn.feature_extraction.text import CountVectorizer\n","import re\n","import kagglehub\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","\n","path = kagglehub.dataset_download(\"kazanova/sentiment140\")\n","nl.download('stopwords')\n","nl.download('wordnet')\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","id":"897fbec0","metadata":{"id":"897fbec0"},"source":["Defining a Logistic Regression class using Pytorch's neural network"]},{"cell_type":"code","execution_count":null,"id":"02b92ceb","metadata":{"id":"02b92ceb"},"outputs":[],"source":["class LogisticRegression(nn.Module):\n","    def __init__(self, input_dim):\n","        super(LogisticRegression, self).__init__()\n","        self.linear = nn.Linear(input_dim, 1)\n","\n","    def forward(self, x):\n","        return torch.sigmoid(self.linear(x))"]},{"cell_type":"markdown","id":"74e0f26b","metadata":{"id":"74e0f26b"},"source":["Importing the Sentinment140 database (used for training and validation)"]},{"cell_type":"code","execution_count":null,"id":"ab92525c","metadata":{"id":"ab92525c"},"outputs":[],"source":["columns = ['target', 'ids', 'date', 'flag', 'user', 'text']\n","sent_df_path = folder_path + \"training.1600000.processed.noemoticon.csv\"\n","sent_df = pd.read_csv(sent_df_path, encoding='latin-1', header=None, names=columns)"]},{"cell_type":"markdown","id":"3f0dd110","metadata":{"id":"3f0dd110"},"source":["Cleaning the database to only include positive and negative labels"]},{"cell_type":"code","execution_count":null,"id":"02e49def","metadata":{"id":"02e49def"},"outputs":[],"source":["sent_df = sent_df[sent_df['target'].isin([0,4])]\n","sent_df['label'] = sent_df['target'].map({0: 0, 4: 1})\n","\n","sent_df = sent_df.sample(250000, random_state=72)\n","\n","X_train = sent_df['text'].tolist()\n","y_train = sent_df['label'].tolist()"]},{"cell_type":"markdown","id":"6cf64fa7","metadata":{"id":"6cf64fa7"},"source":["Processing the lyrics of the spotify database into tokens. Used later when we predict the sentinment"]},{"cell_type":"code","execution_count":null,"id":"956f94c0","metadata":{"id":"956f94c0","outputId":"c0e2c892-b4f2-4692-885d-204a4a289d1e"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\jenni\\AppData\\Local\\Temp\\ipykernel_26272\\2513219802.py:1: DtypeWarning: Columns (6,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24) have mixed types. Specify dtype option on import or set low_memory=False.\n","  spotify = pd.read_csv(\"spotifydata_translated_combined.csv\")\n"]}],"source":["save_path = folder_path + \"spotifydata_translated_combined.csv\"\n","spotify = pd.read_csv(save_path)\n","\n","stop_words = stopwords.words('english')\n","lemmatizer = WordNetLemmatizer()\n","def preprocess(text):\n","    #removes section headers\n","    text = re.sub(r\"\\[[^\\]]+\\]\", \"\", text)\n","    tokens = []\n","\n","    for word in simple_preprocess(text, deacc=True):\n","        if word not in stop_words:\n","            tokens.append(lemmatizer.lemmatize(word))\n","\n","    return tokens\n","\n","spotify['tokens'] = spotify['lyrics'].astype(str).apply(preprocess)"]},{"cell_type":"code","execution_count":null,"id":"7af3e449","metadata":{"id":"7af3e449"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","sent_df['tokens'] = sent_df['text'].apply(preprocess)\n","X_texts = sent_df['tokens'].apply(lambda tokens: ' '.join(tokens))\n","y = sent_df['label'].values\n","\n","vectorizer = TfidfVectorizer(max_features=10000, min_df=10)\n","X = vectorizer.fit_transform(X_texts).toarray()\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"]},{"cell_type":"markdown","id":"6e76776a","metadata":{"id":"6e76776a"},"source":["Converting training/validation split into Pytorch Tensors for model training"]},{"cell_type":"code","execution_count":null,"id":"b232e361","metadata":{"id":"b232e361"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n","y_train_tensor = torch.tensor(y_train.reshape(-1, 1), dtype=torch.float32).to(device)\n","\n","X_val_tensor = torch.tensor(X_val, dtype=torch.float32).to(device)\n","y_val_tensor = torch.tensor(y_val.reshape(-1, 1), dtype=torch.float32).to(device)"]},{"cell_type":"code","execution_count":null,"id":"a7680bae","metadata":{"id":"a7680bae","outputId":"798be74b-a059-49a4-8afd-a20fe039de67"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/150, Loss: 0.7233\n","Epoch 2/150, Loss: 0.6695\n","Epoch 3/150, Loss: 0.6574\n","Epoch 4/150, Loss: 0.6428\n","Epoch 5/150, Loss: 0.6302\n","Epoch 6/150, Loss: 0.6234\n","Epoch 7/150, Loss: 0.6215\n","Epoch 8/150, Loss: 0.6211\n","Epoch 9/150, Loss: 0.6198\n","Epoch 10/150, Loss: 0.6171\n","Epoch 11/150, Loss: 0.6136\n","Epoch 12/150, Loss: 0.6106\n","Epoch 13/150, Loss: 0.6086\n","Epoch 14/150, Loss: 0.6077\n","Epoch 15/150, Loss: 0.6072\n","Epoch 16/150, Loss: 0.6067\n","Epoch 17/150, Loss: 0.6059\n","Epoch 18/150, Loss: 0.6048\n","Epoch 19/150, Loss: 0.6037\n","Epoch 20/150, Loss: 0.6027\n","Epoch 21/150, Loss: 0.6021\n","Epoch 22/150, Loss: 0.6017\n","Epoch 23/150, Loss: 0.6014\n","Epoch 24/150, Loss: 0.6011\n","Epoch 25/150, Loss: 0.6006\n","Epoch 26/150, Loss: 0.6000\n","Epoch 27/150, Loss: 0.5995\n","Epoch 28/150, Loss: 0.5991\n","Epoch 29/150, Loss: 0.5988\n","Epoch 30/150, Loss: 0.5985\n","Epoch 31/150, Loss: 0.5983\n","Epoch 32/150, Loss: 0.5981\n","Epoch 33/150, Loss: 0.5978\n","Epoch 34/150, Loss: 0.5975\n","Epoch 35/150, Loss: 0.5972\n","Epoch 36/150, Loss: 0.5970\n","Epoch 37/150, Loss: 0.5968\n","Epoch 38/150, Loss: 0.5966\n","Epoch 39/150, Loss: 0.5964\n","Epoch 40/150, Loss: 0.5962\n","Epoch 41/150, Loss: 0.5960\n","Epoch 42/150, Loss: 0.5959\n","Epoch 43/150, Loss: 0.5957\n","Epoch 44/150, Loss: 0.5956\n","Epoch 45/150, Loss: 0.5955\n","Epoch 46/150, Loss: 0.5954\n","Epoch 47/150, Loss: 0.5953\n","Epoch 48/150, Loss: 0.5951\n","Epoch 49/150, Loss: 0.5950\n","Epoch 50/150, Loss: 0.5949\n","Epoch 51/150, Loss: 0.5948\n","Epoch 52/150, Loss: 0.5947\n","Epoch 53/150, Loss: 0.5946\n","Epoch 54/150, Loss: 0.5945\n","Epoch 55/150, Loss: 0.5944\n","Epoch 56/150, Loss: 0.5943\n","Epoch 57/150, Loss: 0.5943\n","Epoch 58/150, Loss: 0.5942\n","Epoch 59/150, Loss: 0.5941\n","Epoch 60/150, Loss: 0.5940\n","Epoch 61/150, Loss: 0.5939\n","Epoch 62/150, Loss: 0.5939\n","Epoch 63/150, Loss: 0.5938\n","Epoch 64/150, Loss: 0.5938\n","Epoch 65/150, Loss: 0.5937\n","Epoch 66/150, Loss: 0.5936\n","Epoch 67/150, Loss: 0.5936\n","Epoch 68/150, Loss: 0.5935\n","Epoch 69/150, Loss: 0.5935\n","Epoch 70/150, Loss: 0.5934\n","Epoch 71/150, Loss: 0.5934\n","Epoch 72/150, Loss: 0.5933\n","Epoch 73/150, Loss: 0.5933\n","Epoch 74/150, Loss: 0.5932\n","Epoch 75/150, Loss: 0.5932\n","Epoch 76/150, Loss: 0.5931\n","Epoch 77/150, Loss: 0.5931\n","Epoch 78/150, Loss: 0.5930\n","Epoch 79/150, Loss: 0.5930\n","Epoch 80/150, Loss: 0.5929\n","Epoch 81/150, Loss: 0.5929\n","Epoch 82/150, Loss: 0.5928\n","Epoch 83/150, Loss: 0.5928\n","Epoch 84/150, Loss: 0.5928\n","Epoch 85/150, Loss: 0.5927\n","Epoch 86/150, Loss: 0.5927\n","Epoch 87/150, Loss: 0.5926\n","Epoch 88/150, Loss: 0.5926\n","Epoch 89/150, Loss: 0.5926\n","Epoch 90/150, Loss: 0.5925\n","Epoch 91/150, Loss: 0.5925\n","Epoch 92/150, Loss: 0.5925\n","Epoch 93/150, Loss: 0.5924\n","Epoch 94/150, Loss: 0.5924\n","Epoch 95/150, Loss: 0.5924\n","Epoch 96/150, Loss: 0.5923\n","Epoch 97/150, Loss: 0.5923\n","Epoch 98/150, Loss: 0.5923\n","Epoch 99/150, Loss: 0.5922\n","Epoch 100/150, Loss: 0.5922\n","Epoch 101/150, Loss: 0.5922\n","Epoch 102/150, Loss: 0.5922\n","Epoch 103/150, Loss: 0.5921\n","Epoch 104/150, Loss: 0.5921\n","Epoch 105/150, Loss: 0.5921\n","Epoch 106/150, Loss: 0.5920\n","Epoch 107/150, Loss: 0.5920\n","Epoch 108/150, Loss: 0.5920\n","Epoch 109/150, Loss: 0.5920\n","Epoch 110/150, Loss: 0.5919\n","Epoch 111/150, Loss: 0.5919\n","Epoch 112/150, Loss: 0.5919\n","Epoch 113/150, Loss: 0.5919\n","Epoch 114/150, Loss: 0.5919\n","Epoch 115/150, Loss: 0.5918\n","Epoch 116/150, Loss: 0.5918\n","Epoch 117/150, Loss: 0.5918\n","Epoch 118/150, Loss: 0.5918\n","Epoch 119/150, Loss: 0.5917\n","Epoch 120/150, Loss: 0.5917\n","Epoch 121/150, Loss: 0.5917\n","Epoch 122/150, Loss: 0.5917\n","Epoch 123/150, Loss: 0.5917\n","Epoch 124/150, Loss: 0.5916\n","Epoch 125/150, Loss: 0.5916\n","Epoch 126/150, Loss: 0.5916\n","Epoch 127/150, Loss: 0.5916\n","Epoch 128/150, Loss: 0.5916\n","Epoch 129/150, Loss: 0.5915\n","Epoch 130/150, Loss: 0.5915\n","Epoch 131/150, Loss: 0.5915\n","Epoch 132/150, Loss: 0.5915\n","Epoch 133/150, Loss: 0.5915\n","Epoch 134/150, Loss: 0.5915\n","Epoch 135/150, Loss: 0.5914\n","Epoch 136/150, Loss: 0.5914\n","Epoch 137/150, Loss: 0.5914\n","Epoch 138/150, Loss: 0.5914\n","Epoch 139/150, Loss: 0.5914\n","Epoch 140/150, Loss: 0.5913\n","Epoch 141/150, Loss: 0.5913\n","Epoch 142/150, Loss: 0.5913\n","Epoch 143/150, Loss: 0.5913\n","Epoch 144/150, Loss: 0.5913\n","Epoch 145/150, Loss: 0.5913\n","Epoch 146/150, Loss: 0.5913\n","Epoch 147/150, Loss: 0.5912\n","Epoch 148/150, Loss: 0.5912\n","Epoch 149/150, Loss: 0.5912\n","Epoch 150/150, Loss: 0.5912\n"]}],"source":["model = LogisticRegression(input_dim=X.shape[1]).to(device)\n","criterion = nn.BCEWithLogitsLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=1)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.8)\n","\n","num_epochs = 150\n","for epoch in range(num_epochs):\n","    model.train()\n","    optimizer.zero_grad()\n","    outputs = model(X_train_tensor)\n","    loss = criterion(outputs, y_train_tensor)\n","    loss.backward()\n","    optimizer.step()\n","\n","    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}\")\n","    scheduler.step()"]},{"cell_type":"code","execution_count":null,"id":"7200afc3","metadata":{"id":"7200afc3","outputId":"a1054f0c-601f-4f74-8f90-849031fa34bc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Validation Accuracy: 0.7354\n"]}],"source":["model.eval()\n","with torch.no_grad():\n","    preds = model(X_val_tensor)\n","    predicted_labels = (preds > 0.5).float()\n","    accuracy = (predicted_labels == y_val_tensor).float().mean().item()\n","    print(f\"Accuracy: {accuracy:.4f}\")\n"]},{"cell_type":"markdown","id":"3a8d95ed","metadata":{"id":"3a8d95ed"},"source":["Saving the model"]},{"cell_type":"code","execution_count":null,"id":"f5d30b3b","metadata":{"id":"f5d30b3b","outputId":"b3406a55-b7cf-42a0-f0e3-5f33b07b8952"},"outputs":[{"data":{"text/plain":["['tfdif_vectorizer.pkl']"]},"execution_count":257,"metadata":{},"output_type":"execute_result"}],"source":["import joblib\n","import torch\n","\n","model_path = folder_path + \"sentiment_model.pt\"\n","vectorization_path = folder_path + \"tfdif_vectorizer.pkl\"\n","\n","torch.save(model.state_dict(), model_path)\n","joblib.dump(vectorizer, vectorization_path)"]},{"cell_type":"markdown","id":"1da2aa8e","metadata":{"id":"1da2aa8e"},"source":["Applying model to spotify data, adding values (no labels, just a value) and then saving."]},{"cell_type":"code","execution_count":null,"id":"88bcdcee","metadata":{"id":"88bcdcee"},"outputs":[],"source":["model_path = folder_path + \"sentiment_model.pt\"\n","vectorization_path = folder_path + \"tfdif_vectorizer.pkl\"\n","\n","model = LogisticRegression(input_dim=10000)\n","model.load_state_dict(torch.load(model_path))\n","model.to(device)\n","model.eval()\n","\n","vectorizer = joblib.load(vectorization_path)"]},{"cell_type":"code","execution_count":null,"id":"17f0b1ff","metadata":{"id":"17f0b1ff"},"outputs":[],"source":["def predict_sentiment(lyrics):\n","    tokens = preprocess(lyrics)\n","    text_vector = vectorizer.transform([' '.join(tokens)])\n","    text_tensor = torch.tensor(text_vector.toarray(), dtype=torch.float32)\n","    with torch.no_grad():\n","        output = model(text_tensor)\n","        score = torch.sigmoid(output).item()\n","\n","    return score"]},{"cell_type":"code","execution_count":null,"id":"9b6cda56","metadata":{"id":"9b6cda56"},"outputs":[],"source":["spotify['senti_score'] = spotify['lyrics'].apply(predict_sentiment)"]},{"cell_type":"code","execution_count":null,"id":"b2d62ac8","metadata":{"id":"b2d62ac8"},"outputs":[],"source":["save_sentiment_path = folder_path + \"2_spotify_sentiment.csv\"\n","spotify.to_csv(save_sentiment_path)"]}],"metadata":{"kernelspec":{"display_name":"lda-env","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}